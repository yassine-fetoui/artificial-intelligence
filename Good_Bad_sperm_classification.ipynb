{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1NmVODbtqJKGGZjHROtFlxneo8zCllVBs",
      "authorship_tag": "ABX9TyOV7ab40FcQJzf1Nk6aAD0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassine-fetoui/artificial-intelligence/blob/main/Good_Bad_sperm_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0rVrBP7Gnfg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "kre2KxQSc9Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_sperm_count=len(os.listdir('/content/drive/MyDrive/High Quality Sperm - Labeled/Bad Sperm'))\n",
        "good_sperm_count=len(os.listdir('/content/drive/MyDrive/High Quality Sperm - Labeled/Good Sperm'))"
      ],
      "metadata": {
        "id": "CE3yjPoSUjz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'Category': ['Bad Sperm', 'Good Sperm'],\n",
        "    'Count': [bad_sperm_count, good_sperm_count]\n",
        "})"
      ],
      "metadata": {
        "id": "n6JzYr4gdGUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "WEYBCei4dOqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x=data['Category'], y=data['Count'] , hue=data['Count'])\n",
        "plt.title(\"Count of images in each categoy\")\n",
        "plt.xlabel(\"Sperm Quality\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxZY6RIjxnu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(data['Count'],labels=data[\"Category\"],autopct='%5.1f%%', startangle=45)\n",
        "#plt.axis('equal')\n",
        "plt.title(\"Count of images in each categoy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9h7OyxwpMSOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "5hP8_DbdhLyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_from_dir(path, num_image, title):\n",
        "  images=os.listdir(path)[:num_image]\n",
        "  plt.figure(figsize=(15,6))\n",
        "  plt.suptitle(title,fontsize=16)\n",
        "  for i , img in enumerate(images):\n",
        "    imgf=os.path.join(path,img)\n",
        "    imgo=Image.open(imgf)\n",
        "    plt.subplot(1,num_image,i+1)\n",
        "    plt.imshow(imgo)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Image {i+1}')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "x_aASAY6f92W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image_from_dir('/content/drive/MyDrive/High Quality Sperm - Labeled/Bad Sperm', 5, 'Bad Sperm')\n",
        "display_image_from_dir('/content/drive/MyDrive/High Quality Sperm - Labeled/Good Sperm', 5, 'Good Sperm')"
      ],
      "metadata": {
        "id": "TZ5Jfxtrhm3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_sperm_image=[os.path.join('/content/drive/MyDrive/High Quality Sperm - Labeled/Bad Sperm', img )\n",
        "for img in os.listdir('/content/drive/MyDrive/High Quality Sperm - Labeled/Bad Sperm')]\n",
        "good_sperm_image=[os.path.join('/content/drive/MyDrive/High Quality Sperm - Labeled/Good Sperm', img )\n",
        "for img in os.listdir('/content/drive/MyDrive/High Quality Sperm - Labeled/Good Sperm')]\n",
        "\n",
        "\n",
        "bad_sperm_df=pd.DataFrame({'image':bad_sperm_image, 'label':'bad'})\n",
        "good_sperm_df=pd.DataFrame({'image':good_sperm_image, 'label':'good'})\n",
        "\n",
        "df=pd.concat([bad_sperm_df, good_sperm_df], axis=0,ignore_index=True) # 123/456 ignore"
      ],
      "metadata": {
        "id": "Itwuzn06j6_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "id": "0hPkpk5SlfO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "XSYnO2Z1lojH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "LPCKeHnsnBjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n"
      ],
      "metadata": {
        "id": "I05g_cq4luVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "iNq0Ckfkn9MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "ros=RandomOverSampler(random_state=42)\n",
        "X_res,y_res=ros.fit_resample(df[['image']],df['label'])"
      ],
      "metadata": {
        "id": "vmm2bsPomDCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_res.shape"
      ],
      "metadata": {
        "id": "dcbBIJPEnYzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_res"
      ],
      "metadata": {
        "id": "lOUbd_QznkE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_res.describe()"
      ],
      "metadata": {
        "id": "dSjeUJjFnc9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bala_train_df=pd.concat([X_res,y_res],axis=1)"
      ],
      "metadata": {
        "id": "RYRGNPVHoFzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bala_train_df[\"image\"][0]"
      ],
      "metadata": {
        "id": "t9jrLlfZoP7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bala_train_df"
      ],
      "metadata": {
        "id": "SpTorcZMq7cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_df, temp_df= train_test_split(bala_train_df, test_size=0.2, random_state=42, stratify=bala_train_df['label'] )\n",
        "val_df, test_df= train_test_split(temp_df, test_size=0.5, random_state=42 , stratify=temp_df['label'])\n",
        "\n",
        "\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ],
      "metadata": {
        "id": "7QjGfl5JoWkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size =(224,224)\n",
        "batch_size=32\n",
        "\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_gen=train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='image',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "\n",
        ")\n",
        "\n",
        "val_gen=val_test_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='image',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "test_gen=val_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='image',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "A8A2nff0rFYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ceil(len(df)/32)"
      ],
      "metadata": {
        "id": "NUwizWuowvQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "  def __init__(self, df, batch_size, image_size, shuffle=True):\n",
        "    self.df=df\n",
        "    self.batch_size=batch_size\n",
        "    self.image_size=image_size,\n",
        "    self.shuffle=shuffle\n",
        "    self.on_epoch_end()\n",
        "  def __data_generation(self,batch) :\n",
        "    X=np.empty((self.batch_size,*self.image_size,3))\n",
        "    y=np.empty((self.batch_size),dtype=int)\n",
        "\n",
        "    for i,path in enumerate(batch['image']):\n",
        "      img=cv2.imread(path)\n",
        "      img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "      img=cv2.resize(img,self.image_size)\n",
        "      X[i]=img/255.0\n",
        "      y[i]=1 if batch.iloc[i]['label']=='good' else 0\n",
        "    return X,y\n",
        "\n",
        "  def __len__(self):\n",
        "      return int(np.ceil(len(self.df)/self.batch_size))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "      self.indexs=index[self.index*batch_size : (index+1)*batch_size]\n",
        "      batch=self.df.iloc[self.indexs]\n",
        "      X,y=self.__data_generation(batch)\n",
        "      return X,y\n",
        "  def on_epoch_end(self):\n",
        "      self.indexs=np.arange(len(self.df))\n",
        "      if self.shuffle:\n",
        "        np.random.shuffle(self.indexs)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eSD63rrlvgB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rab2qpBmxe4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=(255,255)\n",
        "batch_size=32\n",
        "train_generator = DataGenerator(train_df, batch_size=batch_size,\n",
        "image_size=image_size)\n",
        "validation_generator = DataGenerator(val_df, batch_size=batch_size,\n",
        "image_size=image_size)\n"
      ],
      "metadata": {
        "id": "S_stSLllwmZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "9s7PgG7t6ncF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_size=(224, 224, 3)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "unet = build_unet(input_shape)\n",
        "\n",
        "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "steps_per_epoch = len(train_generator)\n",
        "validation_steps = len(validation_generator)"
      ],
      "metadata": {
        "id": "WW9vmPR46kb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet.summary()"
      ],
      "metadata": {
        "id": "Wek8j_SY6p2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_generator)\n",
        "validation_steps = len(validation_generator)"
      ],
      "metadata": {
        "id": "uuJ2bW4Y7Gf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROZlvSUt84NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet.fit(\n",
        " train_generator,\n",
        " validation_data=validation_generator,\n",
        " epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "akaXcmm27BIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}